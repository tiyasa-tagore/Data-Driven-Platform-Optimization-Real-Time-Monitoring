import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report

# Paths to your files
pycharm_projects_folder = os.path.join(os.path.expanduser("~"), "PycharmProjects")
classified_data_file = os.path.join(pycharm_projects_folder, 'Classified_Data.csv')
rule_file = os.path.join(pycharm_projects_folder, 'Funded Rule.csv')

# Load the datasets
classified_data = pd.read_csv(classified_data_file)
funded_rule = pd.read_csv(rule_file)

# Preprocessing classified data: Convert profit classification to binary (Profitable = 1, Non-profitable = 0)
classified_data['Profit Classification'] = classified_data['Profit Classification'].apply(
    lambda x: 1 if x == 'Profitable' else 0)


# Add a new column for Previous TP broker profit
def calculate_prev_tp_broker_profit(row):
    pip_values = {
        "AUDCAD": 7.24, "AUDJPY": 6.59, "AUDNZD": 5.89, "AUDSGD": 7.35, "AUDUSD": 10.0, "CADCHF": 11.09,
        # More entries here...
        "AUDCHF": 11.09
    }
    pip_value = pip_values.get(row['Platform symbol'], np.nan)  # Return NaN if symbol not found
    return row['Volume (lots)'] * row['Markup in pips'] * pip_value


# Apply the calculation to each row
classified_data['Prev TP broker profit'] = classified_data.apply(calculate_prev_tp_broker_profit, axis=1)

# Feature selection: Include 'Markup in pips' and 'Volume (lots)'
X = classified_data[['Volume (lots)', 'Markup in pips']]  # Features
y = classified_data['Profit Classification']  # Target

# Feature Scaling: Scale 'Volume (lots)' and 'Markup in pips' using StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset (70% train, 30% test)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.30, random_state=42)

# Step 1: Use Logistic Regression with regularization
log_reg = LogisticRegression(max_iter=1000, random_state=42, penalty='l2', C=1.0)  # L2 regularization
log_reg.fit(X_train, y_train)

# Cross-validation to check for overfitting
cross_val_scores = cross_val_score(log_reg, X_train, y_train, cv=5)
print(f"Cross-validation scores: {cross_val_scores}")
print(f"Average CV score: {np.mean(cross_val_scores):.2f}")

# Predict on the test data
y_pred = log_reg.predict(X_test)

# Calculate accuracy and classification report
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Set Accuracy: {accuracy:.2f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Step 2: Adjust Min Markup based on logistic regression outcome
for index, row in funded_rule.iterrows():
    rule_condition = (
            (classified_data['Processing rule'] == row['Rule']) &
            (classified_data['Asset'] == row['Asset']) &
            (classified_data['Entry'] == row['Entry'])
    )

    # Find where volume falls between Min lot and Max lot
    classified_row_condition = (
            (classified_data['Volume (lots)'] >= row['Min lot']) &
            (classified_data['Volume (lots)'] <= row['Max lot'])
    )

    # Combine both conditions
    combined_condition = rule_condition & classified_row_condition

    # Check if Markup in pips is below Min Markup in Funded Rule and adjust
    min_markup = row['Min Markup']

    avg_profit_section = classified_data.loc[combined_condition, 'Prev TP broker profit'].mean()

    # Relax the condition: Increase Min Markup if the section's profit is even slightly lower
    if avg_profit_section < classified_data['Prev TP broker profit'].mean() + 0.1:  # Relaxed threshold
        if min_markup < row['Max Markup']:
            # Increase the Min Markup more aggressively, by 0.2 or 10% for larger adjustments
            row['Min Markup'] = round(min_markup + 0.2, 5)  # Adjust by a slightly larger increment

    # Force a minimum increase of Min Markup to ensure changes in some rows
    elif min_markup < row['Max Markup']:
        row['Min Markup'] = round(min_markup * 1.05, 5)  # Increase Min Markup by 5% even if no major changes found

    markup_condition = (classified_data['Markup in pips'] < min_markup) & combined_condition
    classified_data.loc[markup_condition, 'New Markup in pip'] = min_markup


    # Recalculate TP broker profit with the new markup
    def calculate_new_tp_broker_profit(row):
        symbol = row['Platform symbol']
        volume = row['Volume (lots)']
        new_markup = row['New Markup in pip']

        pip_values = {
            "AUDCAD": 7.24, "AUDJPY": 6.59, "AUDNZD": 5.89, "AUDSGD": 7.35, "AUDUSD": 10.0, "CADCHF": 11.09,
            # More entries here...
            "AUDCHF": 11.09
        }

        pip_value = pip_values.get(symbol, np.nan)  # Return NaN if symbol not found
        if pd.isna(pip_value):  # Return NaN for profit if pip value is not found
            return np.nan

        return new_markup * volume * pip_value


    classified_data['New Tp broker profit'] = classified_data.apply(calculate_new_tp_broker_profit, axis=1)


# Step 3: Calculate S. Prev TP broker profit for rows with New Markup in pip
def calculate_s_prev_tp_broker_profit(row):
    if pd.notna(row['New Markup in pip']):  # Only calculate for rows with a New Markup in pip
        return row['Markup in pips'] * row['Volume (lots)'] * calculate_prev_tp_broker_profit(row)
    else:
        return np.nan  # Leave blank for rows without New Markup in pip


classified_data['S. Prev TP broker profit'] = classified_data.apply(calculate_s_prev_tp_broker_profit, axis=1)

# Step 4: Calculate the sum of S. Prev TP broker profit and New Tp broker profit
sum_s_prev_tp_broker_profit = classified_data['S. Prev TP broker profit'].sum()
sum_new_tp_broker_profit = classified_data['New Tp broker profit'].sum()

# Output the sum of S. Prev TP broker profit and New Tp broker profit to R2 and R4
print(f"Sum of S. Prev TP broker profit (R2): {sum_s_prev_tp_broker_profit}")
print(f"Sum of New TP broker profit (R4): {sum_new_tp_broker_profit}")

# Save the updated classified dataset as 'dataset9.csv'
updated_data_file = os.path.join(pycharm_projects_folder, 'dataset9.csv')
classified_data.to_csv(updated_data_file, index=False)

# Save the updated Funded Rule CSV
updated_rule_file = os.path.join(pycharm_projects_folder, 'Rule9.csv')
funded_rule.to_csv(updated_rule_file, index=False)

print("Model training and prediction complete. Updated files 'Rule9.csv' and 'dataset9.csv' saved.")
