import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Step 1: Define paths for input and output files
pycharm_projects_folder = os.path.join(os.path.expanduser("~"), "PycharmProjects")
input_file = os.path.join(pycharm_projects_folder, 'Commodities_Data.csv')  # Correct filename with extension
output_predictions_file = os.path.join(pycharm_projects_folder,
                                       "Min_Markup_Predictions_Commodities.csv")  # Output file for predictions

# Step 2: Load the dataset
trading_data_df = pd.read_csv(input_file)

# Step 3: Preprocessing - Strip spaces from column names, and ensure proper data types
trading_data_df.columns = trading_data_df.columns.str.strip()

# Convert 'Updated Date & Time' to datetime format
trading_data_df['Updated Date & Time'] = pd.to_datetime(trading_data_df['Updated Date & Time'], errors='coerce')

# Convert 'Volume (lots)' and 'Markup in pips' to numeric
trading_data_df['Volume (lots)'] = pd.to_numeric(trading_data_df['Volume (lots)'], errors='coerce')
trading_data_df['Markup in pips'] = pd.to_numeric(trading_data_df['Markup in pips'], errors='coerce')

# Step 4: Define rules for Commodities (Market Open, London Open, NY Open, Regular, Late Trading Hours)
rule_conditions_commodities = {
    'Market Open Hour': [
        (30, 40, 0.1, 0.22),
        (20, 29.99, 0.09, 0.16),
        (10, 19.99, 0.05, 0.12),
        (5, 9.99, 0.03, 0.07),
        (2, 4.99, 0.01, 0.05),
        (0.01, 1.99, 0, 0.02)
    ],
    'London Open': [
        (30, 40, 0.08, 0.19),
        (20, 29.99, 0.08, 0.16),
        (10, 19.99, 0.05, 0.11),
        (5, 9.99, 0.02, 0.06),
        (2, 4.99, 0.01, 0.04),
        (0.01, 1.99, 0, 0.02)
    ],
    'NY Open': [
        (30, 40, 0.08, 0.19),
        (20, 29.99, 0.08, 0.16),
        (10, 19.99, 0.05, 0.11),
        (5, 9.99, 0.02, 0.06),
        (2, 4.99, 0.01, 0.04),
        (0.01, 1.99, 0, 0.02)
    ],
    'Regular': [
        (30, 40, 0.08, 0.19),
        (20, 29.99, 0.08, 0.14),
        (10, 19.99, 0.05, 0.09),
        (5, 9.99, 0.02, 0.05),
        (2, 4.99, 0.01, 0.03),
        (0.01, 1.99, 0, 0.01)
    ],
    'Late Trading Hours': [
        (20, 40, 0.09, 0.22),
        (10, 19.99, 0.08, 0.18),
        (5, 9.99, 0.06, 0.13),
        (2, 4.99, 0.02, 0.08),
        (0.01, 1.99, 0.01, 0.04)
    ]
}


# Step 5: Add Min lot, Max lot, Min Markup, and Max Markup based on processing rule and volume for Commodities
def assign_markup_commodities(row):
    volume = row['Volume (lots)']
    rule = row['Processing rule']

    if row['Asset'] == 'Commodities' and rule in rule_conditions_commodities:
        for condition in rule_conditions_commodities[rule]:
            if condition[0] <= volume <= condition[1]:
                return condition[0], condition[1], condition[2], condition[3]
    return None, None, None, None


# Apply the function to add the columns for Commodities
trading_data_df[['Min lot', 'Max lot', 'Min Markup', 'Max Markup']] = trading_data_df.apply(assign_markup_commodities,
                                                                                            axis=1,
                                                                                            result_type="expand")

# Step 6: Drop rows where Min Markup or Max Markup is missing (non-Commodities or unmatched cases)
trading_data_df = trading_data_df.dropna(subset=['Min Markup', 'Max Markup'])


# Step 7: Prepare the dataset for model training (features and labels)
def can_increase_markup(row):
    if row['Min Markup'] == row['Max Markup']:
        return 0  # No room to increase
    if row['Min Markup'] < row['Max Markup']:
        return 1  # Can increase
    return 0


trading_data_df['Can Increase Markup'] = trading_data_df.apply(can_increase_markup, axis=1)

# Step 8: Split data into features (X) and labels (y)
X = trading_data_df[['Min lot', 'Max lot', 'Min Markup', 'Max Markup']]
y = trading_data_df['Can Increase Markup']

# Step 9: Split the dataset into 70% training and 30% testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 10: Train the model
model = DecisionTreeClassifier()
model.fit(X_train, y_train)

# Step 11: Test the model and calculate accuracy
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Model accuracy: {accuracy * 100:.2f}%")


# Step 12: Predict the new minimum markup for the entire dataset
def update_min_markup(row):
    if row['Can Increase Markup'] == 1 and row['Min Markup'] < row['Max Markup']:
        increment = 0.01  # For commodities, we increment by 0.01
        new_min_markup = row['Min Markup'] + increment
        if new_min_markup < row['Max Markup']:
            return new_min_markup
        return row['Min Markup']
    return row['Min Markup']


trading_data_df['New Min Markup'] = trading_data_df.apply(update_min_markup, axis=1)

# Step 13: Group by 'Processing rule', 'Asset', 'Min lot', and 'Max lot' and assign only one unique New Min Markup
grouped_df = trading_data_df.groupby(['Processing rule', 'Asset', 'Min lot', 'Max lot']).agg({
    'Min Markup': 'first',
    'Max Markup': 'first',
    'New Min Markup': 'mean'  # You can replace 'mean' with 'median' or 'mode' if you prefer
}).reset_index()

# Step 14: Filter the data where the Min Markup has changed (i.e., New Min Markup > Min Markup)
filtered_df = grouped_df[grouped_df['New Min Markup'] > grouped_df['Min Markup']]

# Step 15: Save the results to a CSV (only rows where Min Markup has changed)
results_df = filtered_df[
    ['Processing rule', 'Asset', 'Min lot', 'Max lot', 'Min Markup', 'New Min Markup', 'Max Markup']]
results_df.to_csv(output_predictions_file, index=False)
print(f"Predicted Min Markup for Commodities saved to {output_predictions_file}")
